{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731d0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de28d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(root='./data',\n",
    "                              train=True,\n",
    "                              transform=ToTensor(),\n",
    "                              download=True\n",
    "                            )\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data',\n",
    "                              train=False,\n",
    "                              transform=ToTensor(),\n",
    "                              download=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3cfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca47dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = next(iter(train_dataloader))[0][0].unsqueeze(dim=0)\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32139493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0839, -0.0182, -0.0718,  0.0206, -0.0569,  0.0599, -0.0333, -0.0550,\n",
       "          0.1052, -0.1093]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "class ScratchNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_units, output_shape, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, hidden_units, kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units*6*6, output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = ScratchNetwork(3, 64, 10, 3)\n",
    "model(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02deff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_step(model,\n",
    "               dataloader,\n",
    "               optimizer,\n",
    "               loss_fn,\n",
    "               device\n",
    "              ):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # forward pass\n",
    "        logits = model(X)\n",
    "        y_pred = torch.softmax(logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_fn(logits, y)\n",
    "        acc = accuracy_score(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc\n",
    "        \n",
    "        # zero Grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader) \n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "        \n",
    "def test_step(model,\n",
    "              dataloader,\n",
    "              optimizer,\n",
    "              loss_fn,\n",
    "              device\n",
    "             ):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            \n",
    "            logits = model(X)\n",
    "            y_pred = torch.softmax(logits, dim=1).argmax(dim=1)\n",
    "            \n",
    "            loss = loss_fn(logits, y)\n",
    "            acc = accuracy_score(y_pred, y)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc += acc\n",
    "            \n",
    "        test_loss = test_loss / len(dataloader)\n",
    "        test_acc = test_acc / len(dataloader)\n",
    "        \n",
    "        return test_loss, test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811d41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_dataloader,\n",
    "          test_dataloader,\n",
    "          optimizer,\n",
    "          loss_fn,\n",
    "          device,\n",
    "          epochs\n",
    "         ):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, optimizer, loss_fn, device)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, optimizer, loss_fn, device)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(\n",
    "                f'epoch {epoch} |'\n",
    "                f'train loss: {train_loss:.4f} | train acc: {test_acc:.4f} |'\n",
    "                f'test loss: {test_loss:.4f} | test acc: {test_acc:.4f}'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c1b071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 |train loss: 2.0182 | train acc: 0.3553 |test loss: 1.8085 | test acc: 0.3553\n",
      "epoch 5 |train loss: 1.2438 | train acc: 0.5468 |test loss: 1.3286 | test acc: 0.5468\n",
      "epoch 10 |train loss: 1.0502 | train acc: 0.6300 |test loss: 1.0802 | test acc: 0.6300\n",
      "epoch 15 |train loss: 0.9309 | train acc: 0.6610 |test loss: 0.9882 | test acc: 0.6610\n",
      "epoch 20 |train loss: 0.8528 | train acc: 0.6209 |test loss: 1.0842 | test acc: 0.6209\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, test_dataloader, optimizer, loss_fn, device, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4340ff",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f041de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a45be6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.models.resnet.resnet18(pretrained=False, **kwargs)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566a939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839bccbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ResNet50_Weights' from 'torchvision.models' (/Users/michael.todisco/.pyenv/versions/anaconda3-2021.05/lib/python3.8/site-packages/torchvision/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5112363e93d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50_Weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ResNet50_Weights' from 'torchvision.models' (/Users/michael.todisco/.pyenv/versions/anaconda3-2021.05/lib/python3.8/site-packages/torchvision/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "408dc7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): failed\n",
      "\n",
      "CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/pytorch/osx-64/current_repodata.json>\n",
      "Elapsed: -\n",
      "\n",
      "An HTTP error occurred when trying to retrieve this URL.\n",
      "HTTP errors are often intermittent, and a simple retry will get you on your way.\n",
      "'https//conda.anaconda.org/pytorch/osx-64'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ce085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
